{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"#de3023\"><h1><b>REMINDER: MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"
      ],
      "metadata": {
        "id": "a0KcPP6vxIxJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHnI3vebxH9g"
      },
      "source": [
        "# Notebook 3: Vector Stores, Additional Functionality, and Model Deployment\n",
        "\n",
        " In this notebook, we will explore several advanced functionalities, focusing on how to handle and query (or draw information from) a corpus of data even faster, more accurately, and for larger datasets by creating a Vector Store object. Additionally, we will demonstrate how to deploy the chatbot model, enabling users to upload data and receive informed responses based on the uploaded content.\n",
        "\n",
        "## Notebook Objectives\n",
        "1. **Advanced Features**: Explore additional OpenAI functionalities to enhance the chatbot's performance and user experience.\n",
        "2. **Vector Store Creation**: Learn to upload and process a corpus, and create a Vector Store object to facilitate efficient data querying.\n",
        "3. **Model Deployment**: Implement the deployment of the chatbot model, allowing interaction through a web interface where users can upload data files and get answers from the model.\n",
        "\n",
        "By the end of this notebook, you will have a fully functional chatbot capable of understanding and answering queries based on a given corpus, and you will be able to deploy this model for practical applications. Hopefully you can use it as a study buddy, or at the very least, impress your parents and friends!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import our libraries"
      ],
      "metadata": {
        "id": "I8d4PQ3umaF-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3omHjkzX95Q8",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d841cc36-b23c-4c68-a56e-935b94981e04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.46.1-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.11-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging<26,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.5.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.14.0)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.24.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.44.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.27->streamlit) (2025.6.15)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.25.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.46.1-py3-none-any.whl (10.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyngrok-7.2.11-py3-none-any.whl (25 kB)\n",
            "Downloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: watchdog, pyngrok, pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 pyngrok-7.2.11 streamlit-1.46.1 watchdog-6.0.0\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.91.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.6.15)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "git is already the newest version (1:2.34.1-1ubuntu1.12).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Cloning into 'Andrej-Kaparthy-Reading-List'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (27/27), done.\u001b[K\n",
            "remote: Total 28 (delta 6), reused 0 (delta 0), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (28/28), 30.94 MiB | 24.08 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n"
          ]
        }
      ],
      "source": [
        "#@title Run this to import our libraries\n",
        "!pip install streamlit pyngrok\n",
        "!pip install openai\n",
        "!pip install PyPDF2\n",
        "!pip install tiktoken\n",
        "!apt-get install git\n",
        "\n",
        "import tiktoken\n",
        "from PyPDF2 import PdfReader\n",
        "import openai\n",
        "import os\n",
        "import concurrent\n",
        "import json\n",
        "import ast\n",
        "import pandas as pd\n",
        "from csv import writer\n",
        "from IPython.display import display, Markdown, Latex\n",
        "from scipy import spatial\n",
        "from tqdm import tqdm\n",
        "from termcolor import colored\n",
        "from openai import OpenAI\n",
        "from time import sleep\n",
        "import streamlit as st\n",
        "from tqdm import tqdm\n",
        "from pyngrok import ngrok\n",
        "import textwrap\n",
        "from google.colab import files # for uploading files\n",
        "import shutil # for managing files\n",
        "import time\n",
        "\n",
        "# Default corpus\n",
        "!git clone https://github.com/Pooret/Andrej-Kaparthy-Reading-List.git\n",
        "\n",
        "def display_thread(thread_id):\n",
        "    for message in client.beta.threads.messages.list(thread_id=thread_id):\n",
        "        display(message.content[0].text.value)\n",
        "\n",
        "def get_last_message(thread_id):\n",
        "    for message in client.beta.threads.messages.list(thread_id=thread_id):\n",
        "        return message.content[0].text.value\n",
        "        break\n",
        "\n",
        "def read_pdf(filepath, max_pages = None):\n",
        "    #TO DO: make this work with OCR for scanned PDFs, other document types (e.g. .pptx)\n",
        "    \"\"\"Takes a filepath to a PDF and returns a string of the PDF's contents\"\"\"\n",
        "    # creating a pdf reader object\n",
        "    reader = PdfReader(filepath)\n",
        "    pdf_text = \"\"\n",
        "    page_number = 0\n",
        "    for page in reader.pages:\n",
        "        page_number += 1\n",
        "        if max_pages and (page_number > max_pages):\n",
        "            break\n",
        "        pdf_text += page.extract_text() + f\"\\nPage Number: {page_number}\"\n",
        "    return pdf_text\n",
        "\n",
        "calc_similarity = lambda x, y: 1 - spatial.distance.cosine(x.data[0].embedding, y.data[0].embedding)\n",
        "\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "pd.set_option('display.max_colwidth', 1500)\n",
        "\n",
        "def pretty_print(df):\n",
        "    return display( HTML( df.to_html().replace(\"\\\\n\",\"<br>\") ) )\n",
        "\n",
        "# Make directory for students to upload their files\n",
        "os.makedirs('/content/directory', exist_ok=True)\n",
        "\n",
        "def read_directory(directory):\n",
        "    \"\"\"\n",
        "    Read supported files from a directory and return their content in a DataFrame.\n",
        "\n",
        "    Args:\n",
        "        directory (str): The path to the directory.\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: A DataFrame containing filenames, filepaths, and text content.\n",
        "    \"\"\"\n",
        "    assert os.path.exists(directory)\n",
        "\n",
        "    data = []\n",
        "\n",
        "    for filename in os.listdir(directory):\n",
        "        if filename.endswith(('pdf', 'txt', 'docx', 'pptx')):\n",
        "            filepath = os.path.join(directory, filename)\n",
        "            text = read_file(filepath, 50)\n",
        "            data.append((filename, filepath, text))  # build rows directly\n",
        "\n",
        "    df = pd.DataFrame(data, columns=[\"Filename\", \"Filepath\", \"Text\"])\n",
        "    return df\n",
        "\n",
        "#https://drlee.io/openais-moderation-api-a-step-by-step-guide-to-ensuring-safer-content-d22a649d51ac\n",
        "def serialize(obj):\n",
        "    \"\"\"Recursively walk object's hierarchy.\"\"\"\n",
        "    if isinstance(obj, (bool, int, float, str)):\n",
        "        return obj\n",
        "    elif isinstance(obj, dict):\n",
        "        obj = obj.copy()\n",
        "        for key in obj:\n",
        "            obj[key] = serialize(obj[key])\n",
        "        return obj\n",
        "    elif isinstance(obj, list):\n",
        "        return [serialize(item) for item in obj]\n",
        "    elif isinstance(obj, tuple):\n",
        "        return tuple(serialize(item) for item in obj)\n",
        "    elif hasattr(obj, '__dict__'):\n",
        "        return serialize(obj.__dict__)\n",
        "    else:\n",
        "        return repr(obj)  # Don't know how to handle, convert to string\n",
        "\n",
        "def pretty_print_result(output):\n",
        "    # Serialize the output object\n",
        "    serialized_output = serialize(output.results[0])\n",
        "\n",
        "    # Convert the serialized output to a JSON formatted string with indentation\n",
        "    json_output = json.dumps(serialized_output, indent=2, ensure_ascii=False)\n",
        "    print(json_output)\n",
        "\n",
        "# Ignore warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Vector Stores\n",
        "\n",
        "In the realm of machine learning and artificial intelligence, efficient data retrieval and management are crucial. Gathering and storing information from large datasets can be both time-consuming and expensive, and occupy large amounts of memory on a computer. One powerful method for handling and querying large datasets is through the use of Vector Stores.\n",
        "\n",
        "### What is a Vector Store?\n",
        "\n",
        "A Vector Store is a specialized way to store and retrieve high-dimensional vectors. Remember, vectors are representations of data points in a multi-dimensional space. You might have seen vectors in physics. Here's an example of vectors in 2 dimensions:\n",
        "\n",
        "![image.png](data:image/png;base64,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)\n",
        "\n",
        "Remember that in NLP, our word embedding vectors are much bigger than 2 dimensions. This is because they have to represent millions of words and sentences. Each vector corresponds to a piece of data, such as a sentence, document, or image, that has been transformed into a numerical format using techniques like embeddings.\n",
        "\n",
        "### Why Use Vector Stores?\n",
        "\n",
        "1. **Efficient Similarity Search**: Vector Stores enable fast and efficient similarity searches. When you need to find data points similar to a given query, the Vector Store can quickly identify and retrieve the most relevant items.\n",
        "2. **Scalability**: Handling large volumes of data is easier with Vector Stores. They are optimized for storing and querying millions of vectors.\n",
        "3. **Versatility**: Vector Stores can be used in information retrieval, recommendation systems, natural language processing, and more.\n",
        "\n",
        "### How Vector Stores Work\n",
        "\n",
        "1. **Data Transformation**: Raw data (e.g., text, images) is transformed into vectors using embedding techniques. For text data, this might involve using language models like GPT to convert sentences into vector representations.\n",
        "2. **Indexing**: Vectors are then stored in the Vector Store with a mechanism that supports efficient similarity searches.\n",
        "3. **Querying**: When a query vector is introduced, the Vector Store uses its structure to rapidly find and return vectors that are most similar to the query. This process typically involves calculating the cosine similarity or distance between vectors.\n",
        "\n",
        "### Applications of Vector Stores\n",
        "\n",
        "- **Chatbots and Virtual Assistants**: Enhancing the chatbot's ability to understand and respond to user queries by retrieving relevant information from a vast corpus.\n",
        "- **Recommendation Systems**: Suggesting products, movies, or content based on the similarity of user preferences and behavior.\n",
        "- **Search Engines**: Improving search accuracy by finding documents or images that are contextually similar to the search query.\n",
        "- **Content Clustering**: Grouping similar content together for better organization and analysis."
      ],
      "metadata": {
        "id": "UjkdFleEKC5h"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Is3BseJBHf74"
      },
      "source": [
        "Enough about why vector stores are awesome. Let's get started! Fill in your API key below and remember to keep it secret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWwN1fJNxH9m",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb358c1-0a0a-4130-c64f-b0c081d3bb4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: OPENAI_API_KEY=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\n"
          ]
        }
      ],
      "source": [
        "#@markdown Enter your secret API key below, and save it in a safe place on your computer!\n",
        "api_key = \"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\" # @param {\"type\":\"string\"}\n",
        "\n",
        "%env OPENAI_API_KEY = {api_key}\n",
        "client = OpenAI()\n",
        "model = \"gpt-3.5-turbo\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsA8_W_1xH9m"
      },
      "source": [
        "## Customizing Chatbot Personalities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOfmxdARxH9n"
      },
      "source": [
        "One important way we can modify a chatbot is by customizing its \"personality\", or style.\n",
        "\n",
        "In education, a chatbot’s personality can impact how engaging or motivating it is, how easy it is to use, and the overall learning experience.\n",
        "\n",
        "In the next activity, try designing the personality of your own educational chatbot!\n",
        "\n",
        "For example, your chatbot could be:\n",
        "\n",
        "- A friendly tutor who patiently explains concepts.\n",
        "- A motivational coach who encourages students through challenges.\n",
        "- A curious companion who learns alongside the user.\n",
        "\n",
        "\n",
        "By carefully defining your chatbot’s tone and style you’ll create an AI assistant that enhances learning in a meaningful way.\n",
        "\n",
        "**Discuss**: What are some useful qualities for your chatbot? Are there any teachers or friends that inspire you?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pB7YN-auxH9o"
      },
      "source": [
        "Below, copy-paste the code you used to create an Assistant earlier (in NB1 or NB2), and edit its instructions to customize its style! What style works best for its purpose?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5LcUyIOxH9p"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"(Prisha G) Project Helper\", # Name the assistant\n",
        "\n",
        "    # Prompt the model to answer questions we give it with instructions below.\n",
        "    instructions=\"Don't give me a direct answer, no matter if I ask conceptual or math questions. Prompt me to understanding the concept with explanations.\", # Replace None with your instructions\n",
        "    model=model\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRvD0zClxH9p"
      },
      "source": [
        "Models can react to instructions in surprising ways! Try out your new Assistant below using the `start_conversation` function below, or talk with your Assistant in the [OpenAI Playground](https://platform.openai.com/playground/assistants)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run to define functions to have a conversation\n",
        "\n",
        "# Function to get a response from the assistant within a larger thread\n",
        "def get_assistant_response_from_thread(user_message, assistant, thread):\n",
        "\n",
        "    # Add the user message to the thread\n",
        "    client.beta.threads.messages.create(\n",
        "        thread_id=thread.id,\n",
        "        role=\"user\",\n",
        "        content=user_message\n",
        "    )\n",
        "\n",
        "    # Send message to assistant to generate a response\n",
        "    run = client.beta.threads.runs.create(\n",
        "        thread_id=thread.id,\n",
        "        assistant_id=assistant.id\n",
        "    )\n",
        "\n",
        "  # Wait for run to complete\n",
        "    while True:\n",
        "        run_status = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id\n",
        "        )\n",
        "        if run_status.status == 'completed':\n",
        "            break\n",
        "        elif run_status.status in ['failed', 'cancelled', 'expired']:\n",
        "            print(f\"Run failed with status: {run_status.status}\")\n",
        "            return None\n",
        "        time.sleep(1)  # Check every second\n",
        "\n",
        "    # View messages added to the thread\n",
        "    messages = client.beta.threads.messages.list(\n",
        "        thread_id=thread.id\n",
        "        )\n",
        "\n",
        "    # Find and print the assistant's response\n",
        "    assistant_response = None\n",
        "    for msg in messages.data:\n",
        "        if msg.role == \"assistant\":\n",
        "            assistant_response = msg.content[0].text.value\n",
        "            break\n",
        "\n",
        "    return assistant_response\n",
        "\n",
        "# Function to start and maintain a conversation\n",
        "def start_conversation(assistant):\n",
        "    # Start a new thread for the conversation\n",
        "    thread = client.beta.threads.create()\n",
        "\n",
        "    print(f\"Start chatting with {assistant.name}! Type 'exit' to end the conversation.\") # Adds the asssistant's name\n",
        "\n",
        "    while True:\n",
        "        # Get user input\n",
        "        user_message = input(\"You: \")\n",
        "\n",
        "        # Exit the conversation if the user says \"exit\"\n",
        "        if user_message.lower() == \"exit\":\n",
        "            print(\"Conversation ended.\")\n",
        "            break\n",
        "\n",
        "        # Get and print the assistant's response\n",
        "        assistant_response = get_assistant_response_from_thread(user_message, assistant, thread)\n",
        "        print(f\"Assistant: {assistant_response}\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pVqXTkoD8mLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zqc3BIblxdXY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1978889-1c48-4c22-fca3-7ada1cd14612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start chatting with (Prisha G) Project Helper! Type 'exit' to end the conversation.\n",
            "You: write me an essay\n",
            "Assistant: I'm here to help you with concepts, questions, or problems you might have. What specific topic or question would you like assistance with?\n",
            "You: exit\n",
            "Conversation ended.\n"
          ]
        }
      ],
      "source": [
        "# Talk to your assistant\n",
        "start_conversation(assistant)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6JNab3RxH9q"
      },
      "source": [
        "## Promoting Ethical Use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuh2MwY1xH9q"
      },
      "source": [
        "One of the big risks with LLMs in education is misuse. Think about the Assistants you've created so far. Imagine if you shared them publicly, so that someone besides yourself could access them.\n",
        "\n",
        "**Discuss:**\n",
        "- What are three *positive* ways these Assistants could be used?\n",
        "- What are three *harmful* ways they could be misused?\n",
        "- How can we prevent harmful behaviors?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below, try **changing your Assistant's instructions** to prevent misuse.\n",
        "\n",
        "For example, you could instruct your assistant to:\n",
        "- ask the user what the purpose of the work is\n",
        "- decline certain types of work (for example, tell the assistant to reply a certain way if it is asked about something unethical)\n",
        "- give leading questions instead of a flat-out answer\n",
        "- something else!\n",
        "\n",
        "\n",
        "*Tip*: Think about how your best teachers teach! What style or techniques do they use? 💡"
      ],
      "metadata": {
        "id": "Dnf0qv6H1k2j"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uuzoJrctxH9q"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQWehm0qxH9r"
      },
      "source": [
        "Remember to test your Assistant with a variety of situations.\n",
        "\n",
        "**Discuss:** Do the ethical guardrails help? Do they ever block something incorrectly, making the Assistant less useful?\n",
        "\n",
        "Can you figure out ways to get around the protections you put in place? This process of bypassing ethical guardrails is called **jailbreaking.**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Direct Retrieval via a Vector Store\n",
        "\n",
        "Beyond changing their personalities, another thing Assistants can do is take files directly! We will create a new assistant. This new Assistant, named Helpful Paper Reader will have the `file_search` tool enabled (more on this built-in OpenAI tool [here](https://platform.openai.com/docs/assistants/tools/file-search))."
      ],
      "metadata": {
        "id": "lTlkQULlNZZw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = client.beta.assistants.create(\n",
        "  name=\"(Prisha) Helpful Paper Reader\",\n",
        "  instructions=\"You are a helpful assistant. Use your knowledge base to answer questions.Don't give me a direct answer, no matter if I ask conceptual or math questions. Prompt me to understanding the concept with explanations.\",\n",
        "  model=model,\n",
        "  tools=[{\"type\": \"file_search\"}],\n",
        ")"
      ],
      "metadata": {
        "id": "nU8yqX-odQ7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Once the `file_search` tool has been enabled, the model will decide when to retrieve content based on the users messages. To access your files, the `file_search` tool will use the Vector Store object that we are creating below."
      ],
      "metadata": {
        "id": "xde3LyyUekuS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Make a Vector Store\n",
        "As we've seen, vector stores (also known as vector databases or vector indexes) are structures designed to store and retrieve high-dimensional vectors efficiently.\n",
        "\n",
        "In this project, we want to use our Assistant to be a paper reader. To do this, we will use a vector store to store embeddings of text documents (e.g. PDFs). These embeddings are generated using a language model, which converts the textual content into fixed-length vectors that capture the meaning of the text."
      ],
      "metadata": {
        "id": "53RsybUod80v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's try to create an empty vector store as an example. You can name it whatever you like, but pick something helpful/relevant to what the vector store will do."
      ],
      "metadata": {
        "id": "PXNWDS82cjfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vector_store_name = \"Andrej Kaparthy Reading List\" # FILL IN HERE\n",
        "vector_store = client.vector_stores.create(name=vector_store_name)"
      ],
      "metadata": {
        "id": "KORJKQ5McrYJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now give our Assistant's `file_search` tool access to the vector store that we just created so that it can look up information from the vector store."
      ],
      "metadata": {
        "id": "8mezAbP_cw5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Update our assistant with the Vector Store object\n",
        "assistant = client.beta.assistants.update(\n",
        "    assistant_id=assistant.id,\n",
        "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}}\n",
        ")"
      ],
      "metadata": {
        "id": "5I-nyzcybfx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's go ahead and fill our vector store up with data from a .pdf file of our choice! You can either pick one of the default papers we have given you as an option below, or you can upload your own .pdf file on an academic topic of your choosing."
      ],
      "metadata": {
        "id": "gvWW54QPc9L4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Choose from the dropdown below!\n",
        "corpus = \"Andrej Kaparthy Reading List\" # @param [\"Choose your corpus!\", \"Upload your files!\", \"Andrej Kaparthy Reading List\"]\n",
        "\n",
        "if corpus == \"Upload your files!\":\n",
        "# Move uploaded files to the created directory\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    shutil.move(filename, '/content/directory/' + filename)\n",
        "\n",
        "if corpus == \"Andrej Kaparthy Reading List\":\n",
        "\n",
        "  source_dir = '/content/Andrej-Kaparthy-Reading-List'\n",
        "  destination_dir = \"/content/directory\"\n",
        "\n",
        "  for filename in os.listdir(source_dir):\n",
        "      if filename.lower().endswith('.pdf'):\n",
        "        source_file = os.path.join(source_dir, filename)\n",
        "        destination_file = os.path.join(destination_dir, filename)\n",
        "        shutil.move(source_file, destination_file)"
      ],
      "metadata": {
        "id": "ivV2-00edLBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Custom Corpus Vector Store\n",
        "\n",
        "Nice job uploading your paper! We will now load this data into Python."
      ],
      "metadata": {
        "id": "IE1tJCK3QVm-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run to load your corpus\n",
        "\n",
        "directory = \"/content/directory\"\n",
        "\n",
        "# Create the vector store\n",
        "vector_store = client.vector_stores.create(name=vector_store_name)\n",
        "\n",
        "# Get all file paths in the directory\n",
        "file_paths = [\n",
        "    os.path.join(directory, filename)\n",
        "    for filename in os.listdir(directory)\n",
        "    if os.path.isfile(os.path.join(directory, filename))\n",
        "]\n",
        "\n",
        "# Open all files as binary streams\n",
        "file_streams = [open(path, \"rb\") for path in file_paths]\n",
        "\n",
        "try:\n",
        "    # Upload and poll the files as a batch to the vector store\n",
        "    file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
        "        vector_store_id=vector_store.id,\n",
        "        files=file_streams\n",
        "    )\n",
        "\n",
        "    # Print the batch upload status and file counts\n",
        "    print(\"Upload batch status:\", file_batch.status)\n",
        "    print(\"File counts:\", file_batch.file_counts)\n",
        "\n",
        "finally:\n",
        "    # Close all file streams to avoid resource leaks\n",
        "    for fs in file_streams:\n",
        "        fs.close()\n",
        "\n",
        "# Link vector store to the assistant\n",
        "assistant = client.beta.assistants.update(\n",
        "  assistant_id=assistant.id,\n",
        "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "usesICV6QVnJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80760edf-d939-4f3f-c20d-328983f00c72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload batch status: completed\n",
            "File counts: FileCounts(cancelled=0, completed=12, failed=0, in_progress=0, total=12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (Optional) Define a Function to Create a Vector Store:\n",
        "\n",
        "Try completing this function to create a vector store and upload your files to it.\n",
        "\n",
        "Fill in the function to name and initialize your vector store, just like you did in the practice cell above."
      ],
      "metadata": {
        "id": "mlMqGW6Voelg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_vector_store(files, vector_store_name=\"Corpus\"):\n",
        "\n",
        "    vector_store_name = None\n",
        "    vector_store = None\n",
        "\n",
        "    file_streams = [(file.name, file) for file in files]\n",
        "    file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "      vector_store_id=vector_store.id, files=file_streams\n",
        "    )\n",
        "    return vector_store"
      ],
      "metadata": {
        "id": "ksQVnzGly1Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing our Vector Store-Based Assistant\n",
        "\n",
        "Now let's try asking our model a question using the information in the vector store. Fill in the input text below:"
      ],
      "metadata": {
        "id": "2BThBv77CTeF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"What special achievement did Andrej achieve and what was it about in the year 2019?\" # TO-DO: Fill in a question\n",
        "\n",
        "# Create thread\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "# Create message, using input text\n",
        "message = client.beta.threads.messages.create(\n",
        "            thread_id=thread.id,\n",
        "            role=\"user\",\n",
        "            content=input_text\n",
        "        )\n",
        "\n",
        "# Create a run for the assistant\n",
        "run = client.beta.threads.runs.create(\n",
        "          thread_id=thread.id,\n",
        "          assistant_id=assistant.id,\n",
        "        )\n",
        "\n",
        "# Wait for run to complete\n",
        "while True:\n",
        "    run_status = client.beta.threads.runs.retrieve(\n",
        "        thread_id=thread.id,\n",
        "        run_id=run.id\n",
        "    )\n",
        "    if run_status.status == 'completed':\n",
        "        break\n",
        "    elif run_status.status in ['failed', 'cancelled', 'expired']:\n",
        "        print(f\"Run failed with status: {run_status.status}\")\n",
        "\n",
        "    time.sleep(1) # Check every second\n",
        "\n",
        "\n",
        "# Get response messages from the thread\n",
        "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "\n",
        "# Extract and display the response\n",
        "message_content = messages[0].content[0].text\n",
        "print(message_content.value) # Print the message text\n",
        "\n"
      ],
      "metadata": {
        "id": "o6N2w_oRCTeG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b800737-ab38-4dde-ea02-67cf495f0358"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I couldn't find specific information about Andrej's special achievement in the year 2019 in the uploaded files. Would you like me to search for something else?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Discuss:** How did the model respond? Did it use the information from your corpus?"
      ],
      "metadata": {
        "id": "rRK6PgJXESBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Extract Response Contents and Citations\n",
        "\n",
        "\n",
        "We can even get the model's citations for its messages. Citations help us understand where in our vector store the information came from."
      ],
      "metadata": {
        "id": "a3uV6QS9qXCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the annotations (references) the model used in its response\n",
        "annotations = message_content.annotations\n",
        "citations = [] # Create list of citations\n",
        "\n",
        "# Loop through annotations to process citations\n",
        "for index, annotation in enumerate(annotations):\n",
        "  # Replace the cited text in the response with its index reference\n",
        "  message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "  # Check if the annotation contains a file citation\n",
        "  if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "      cited_file = client.files.retrieve(file_citation.file_id) # Get the file's details\n",
        "      citations.append(f\"[{index}] {cited_file.filename}\") # Store the citation with its index\n",
        "\n",
        "# Print all collected citations\n",
        "for citation in citations:\n",
        "  print(citation)"
      ],
      "metadata": {
        "id": "AZ_oNgUoDb6J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Interacting with the Assistant\n",
        "\n",
        "Let's put all of that together in a function that takes user input, sends it to the assistant, and retrieves the response along with citations from the uploaded documents. Fill in the code below, and then test out your assistant with citations!"
      ],
      "metadata": {
        "id": "MAiTM9l3D4uS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_assistant_response(assistant, input_text):\n",
        "    # Create thread\n",
        "    thread = client.beta.threads.create()\n",
        "\n",
        "    # Create message and run like before\n",
        "    message = client.beta.threads.messages.create(\n",
        "            thread_id=thread.id,\n",
        "            role=\"user\",\n",
        "            content=input_text\n",
        "        )\n",
        "    # Create run\n",
        "    run = client.beta.threads.runs.create(\n",
        "          thread_id=thread.id,\n",
        "          assistant_id=assistant.id,\n",
        "        )\n",
        "\n",
        "    print(\"Generating response...\")\n",
        "\n",
        "    # Wait for run to complete\n",
        "    while True: # assistant generates thoughts\n",
        "        run_status = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id\n",
        "        )\n",
        "        if run_status.status == 'completed':\n",
        "            break\n",
        "        elif run_status.status in ['failed', 'cancelled', 'expired']:\n",
        "            print(f\"Run failed with status: {run_status.status}\")\n",
        "\n",
        "        time.sleep(1) # Check every second\n",
        "\n",
        "    # Get the messages in the thread (i.e. assistant's responses) and annotations\n",
        "    messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "    message_content = messages[0].content[0].text\n",
        "    annotations = message_content.annotations\n",
        "\n",
        "    # Get citations for work\n",
        "    citations = []\n",
        "    for index, annotation in enumerate(annotations):\n",
        "      message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "      message_content.value = message_content.value.replace(\"\\n\", \" \") # Replace newline characters with spaces\n",
        "      if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "          cited_file = client.files.retrieve(file_citation.file_id)\n",
        "          citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "    # Return message text and citations\n",
        "    return message_content.value, citations # TO-DO: return message text and citations (hint: what variables are these stored in above?)"
      ],
      "metadata": {
        "id": "CchEetvgmiwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test out your vector-store powered assistant!\n",
        "input_text = \"Can you tell me about Andrej Kaparthy's work?\"\n",
        "get_assistant_response(assistant, input_text)"
      ],
      "metadata": {
        "id": "NnB_TRb2FHxq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f14626b8-7a1f-425b-bbe4-78bc7ea47e9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating response...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(\"Andrej Kaparthy's work involves training language models to follow instructions with human feedback and aligning models with human intentions through techniques like reinforcement learning from human feedback (RLHF). This work aims to improve the behavior of language models across various tasks, focusing on aspects like safety, reliability, and alignment with human intentions. Kaparthy's work is influenced by previous research in areas such as alignment, learning from human feedback, and cross-task generalization in language models. Additionally, the evaluation of the harms of language models and the implications for real-world deployment are also considered in this research[0][1].\",\n",
              " ['[0] Training language models to follow instructions with human feedback.pdf',\n",
              "  '[1] Training language models to follow instructions with human feedback.pdf'])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's put these steps in a loop to have conversation with your assistant. Test it out below!"
      ],
      "metadata": {
        "id": "uwUyCXlxsZle"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Run to define a function to have a conversation with your new assistant\n",
        "\n",
        "\n",
        "def start_conversation(assistant):\n",
        "    # Create a new thread for the conversation\n",
        "    thread = client.beta.threads.create()\n",
        "    citations = []  # Keep track of citations across messages\n",
        "\n",
        "    # Greet the user and give exit instructionns\n",
        "    print(f\"Start chatting with {assistant.name}! Type 'exit' to end the conversation.\") # Adds the assistant's name\n",
        "\n",
        "    while True:\n",
        "        # Get user input\n",
        "        input_text = input(\"You: \")\n",
        "\n",
        "        # Exit the conversation if the user types \"exit\"\n",
        "        if input_text.lower() == \"exit\":\n",
        "            print(\"Ending the conversation.\")\n",
        "            break\n",
        "\n",
        "        # Send the user's input as a message\n",
        "        client.beta.threads.messages.create(\n",
        "            thread_id=thread.id,\n",
        "            role=\"user\",\n",
        "            content=input_text\n",
        "        )\n",
        "\n",
        "        # Run the assistant response\n",
        "        run = client.beta.threads.runs.create(\n",
        "            thread_id=thread.id,\n",
        "            assistant_id=assistant.id,\n",
        "        )\n",
        "\n",
        "        # Wait for the assistant to process\n",
        "        # Wait for run to complete\n",
        "        while True:\n",
        "            run_status = client.beta.threads.runs.retrieve(\n",
        "                thread_id=thread.id,\n",
        "                run_id=run.id\n",
        "            )\n",
        "            if run_status.status == 'completed':\n",
        "                break\n",
        "            elif run_status.status in ['failed', 'cancelled', 'expired']:\n",
        "                print(f\"Run failed with status: {run_status.status}\")\n",
        "\n",
        "            time.sleep(1) # Check every second\n",
        "\n",
        "        # Retrieve messages in the run\n",
        "        messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "        message_content = messages[-1].content[0].text  # Get the latest response\n",
        "        annotations = message_content.annotations\n",
        "\n",
        "        # Process annotations to extract citations for the current response\n",
        "        for index, annotation in enumerate(annotations, start=len(citations)):\n",
        "            message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "            message_content.value = message_content.value.replace(\"\\n\", \" \") # Replace newline characters with spaces\n",
        "\n",
        "            # Check for file citations and retrieve file names\n",
        "            if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "                cited_file = client.files.retrieve(file_citation.file_id)\n",
        "                citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "        # Print the assistant's response and cumulative citations\n",
        "        print(\"Assistant's Response:\", message_content.value)\n",
        "        if citations:\n",
        "          print(\"Citations:\", citations)\n"
      ],
      "metadata": {
        "id": "15U4jVoBPL4g",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try talking to your vector store-powered assistant!\n",
        "start_conversation(assistant)"
      ],
      "metadata": {
        "id": "wMAXr7HKPOVW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dc4023-7653-40d2-bd8a-88a738e957f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start chatting with (Prisha) Helpful Paper Reader! Type 'exit' to end the conversation.\n",
            "You: exit\n",
            "Ending the conversation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O21VvxMxH9u"
      },
      "source": [
        "If you want to keep exploring, you can check out additional aspects of the [OpenAI API tools](https://platform.openai.com/docs/assistants/tools)! For example, check out the Text-to-Speech or Speech-to-Text functionality. As a reminder, you can also interact more with your new, vector-store-backed assistant in the [OpenAI Playground](https://platform.openai.com/playground/assistants)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUf63HgPxH9u"
      },
      "source": [
        "## Deploying your Model on Streamlit\n",
        "\n",
        "Congrats on finishing the development of your assistant! Lastly, let's release our Assistants to the world! But before we start, we'll need to set up an ngrok account to connect our app to the Internet!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=SlateGrey><h2><b>\n",
        "Use [these](https://drive.google.com/file/d/12zwuOuKh91VSHIHS-6S4ADF4HLC2wKJq/view?usp=sharing) instructions to create a ngrok account and get your authtoken!\n",
        "</b></h2></font>\n",
        "\n",
        "<font color=DarkGray><h3><b>\n",
        "Paste your authtoken below next to `!ngrok authtoken` and run the cell!\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "</b></h3></font>"
      ],
      "metadata": {
        "id": "q_j5rgf9XyCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ✍ Exercise: Connecting our App and Model\n",
        "\n",
        "Excellent - now we're ready! We will be using streamlit (imported as st) to connect our model to our app. Below are a few examples to help you get started."
      ],
      "metadata": {
        "id": "_qUwKVav--gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up your auth token\n",
        "!ngrok authtoken 2ytQ72kWSeXGUFeolOdXidkyrwz_66q4XT1uqs8g2WTyjvw5o # YOUR AUTHTOKEN HERE\n"
      ],
      "metadata": {
        "id": "CyNwE8MPX3u0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38465fcd-640a-43dc-9ba7-277d7837a174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/.streamlit/"
      ],
      "metadata": {
        "id": "2O10ELkmaqyz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input your API key in the quotes below!"
      ],
      "metadata": {
        "id": "XPlugJaiTaAx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/.streamlit/secrets.toml\n",
        "[secrets]\n",
        "OPENAI_API_KEY = \"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\""
      ],
      "metadata": {
        "id": "POFrEqLgasvl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e96d16-f234-4f31-9607-9cbfcf9370ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/.streamlit/secrets.toml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following code, we redefine the essential functions needed to create a vector store and generate responses from your assistant, including relevant citations. Additionally, we outline the steps to:\n",
        "- Set up your assistant\n",
        "- Upload corpus files\n",
        "- Display interactions between the user and the assistant\n",
        "\n",
        "Fill in your assistant's specific details, such as its name, instructions, and tools, in the section below."
      ],
      "metadata": {
        "id": "Y7Ak2soTzgFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import openai\n",
        "from pyngrok import ngrok\n",
        "import subprocess\n",
        "import sys\n",
        "import io\n",
        "import time\n",
        "from openai import OpenAI\n",
        "from PIL import Image, ImageDraw\n",
        "from time import sleep\n",
        "\n",
        "# Function to create a vector store and upload files\n",
        "def create_vector_store(files):\n",
        "    vector_store_name = \"Corpus\"\n",
        "    vector_store = client.vector_stores.create(name=vector_store_name)\n",
        "    file_streams = [(file.name, file) for file in files]\n",
        "    file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
        "    vector_store_id=vector_store.id, files=file_streams\n",
        ")\n",
        "    return vector_store\n",
        "\n",
        "# Function to get an assistant response\n",
        "def get_assistant_response(assistant, input_text):\n",
        "    thread = client.beta.threads.create()\n",
        "    message = client.beta.threads.messages.create(\n",
        "            thread_id=thread.id,\n",
        "            role=\"user\",\n",
        "            content=input_text\n",
        "        )\n",
        "    run = client.beta.threads.runs.create(\n",
        "          thread_id=thread.id,\n",
        "          assistant_id=assistant.id,\n",
        "        )\n",
        "\n",
        "    # Wait for run to complete\n",
        "    while True:\n",
        "        run_status = client.beta.threads.runs.retrieve(\n",
        "            thread_id=thread.id,\n",
        "            run_id=run.id\n",
        "        )\n",
        "        if run_status.status == 'completed':\n",
        "            break\n",
        "        elif run_status.status in ['failed', 'cancelled', 'expired']:\n",
        "            print(f\"Run failed with status: {run_status.status}\")\n",
        "\n",
        "        time.sleep(1) # Check every second\n",
        "\n",
        "\n",
        "    messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
        "    message_content = messages[0].content[0].text\n",
        "    annotations = message_content.annotations\n",
        "    citations = []\n",
        "\n",
        "    # Get citations for work\n",
        "    for index, annotation in enumerate(annotations):\n",
        "      message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
        "      if file_citation := getattr(annotation, \"file_citation\", None):\n",
        "          cited_file = client.files.retrieve(file_citation.file_id)\n",
        "          citations.append(f\"[{index}] {cited_file.filename}\")\n",
        "\n",
        "    return message_content.value, citations\n",
        "\n",
        "\n",
        "# Set up OpenAI API key\n",
        "openai.api_key = st.secrets[\"secrets\"][\"OPENAI_API_KEY\"]\n",
        "\n",
        "client = OpenAI()\n",
        "model = \"gpt-3.5-turbo\"\n",
        "\n",
        "# ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ FILL IN YOUR ASSISTANT INFO HERE ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "assistant = client.beta.assistants.create( ## TO-DO - FILL IN YOUR ASSISTANT NAME, INSTRUCTIONS, AND TOOLS\n",
        "  name=\"Prisha's AI Chatbot for Education\",\n",
        "  instructions= \"You are an adaptive well-educated teacher who guides students without providing direct answers\"\n",
        "  model=model,\n",
        "  tools=[{\"type\": \"file_search\"}], # FILL IN: What tool does the assistant need to efficiently search files using the vector store?\n",
        ")\n",
        "\n",
        "st.title(\"Content Query Chatbot\")\n",
        "st.subheader(\"Upload some files!\")\n",
        "\n",
        "# File uploader\n",
        "uploaded_files = st.file_uploader(\"Upload PDF files\", type=\"pdf\", accept_multiple_files=True)\n",
        "\n",
        "if uploaded_files:\n",
        "    st.write(\"Files uploaded successfully.\")\n",
        "    vector_store = create_vector_store(uploaded_files)\n",
        "\n",
        "     # Update our assistant with the Vector Store object\n",
        "    assistant = client.beta.assistants.update(\n",
        "        assistant_id=assistant.id,\n",
        "        tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}}\n",
        "    )\n",
        "    # Display uploaded filenames\n",
        "    st.write(\"Uploaded files:\")\n",
        "    for file in uploaded_files:\n",
        "        st.write(f\"- {file.name}\")\n",
        "\n",
        "    # Prompt user to ask a question\n",
        "    query = st.chat_input(\"Ask a question about the uploaded content:\")\n",
        "\n",
        "    if query:\n",
        "        answer, citations = get_assistant_response(assistant, query)\n",
        "\n",
        "        st.chat_message(\"user\").markdown(query)\n",
        "        st.chat_message(\"assistant\").markdown(f\"**Answer:** {answer}\")\n",
        "\n",
        "        st.write(\"Citations:\")\n",
        "        for citation in citations:\n",
        "            st.write(f\"- {citation}\")\n"
      ],
      "metadata": {
        "id": "zfjOVUbbXffm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def launch_website():\n",
        "  print (\"Click this link to try your web app:\")\n",
        "  print (\"If you get an error, wait 5 seconds and click again!\")\n",
        "  public_url = ngrok.connect()\n",
        "  print (public_url)\n",
        "  !streamlit run --server.port 80 app.py >/dev/null\n",
        "\n",
        "# Launch the website!\n",
        "launch_website()"
      ],
      "metadata": {
        "id": "v5iR9leJYUoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1a7ad2c-b98c-4a38-b16b-1d97730897ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Click this link to try your web app:\n",
            "If you get an error, wait 5 seconds and click again!\n",
            "NgrokTunnel: \"https://9dc6-35-203-160-165.ngrok-free.app\" -> \"http://localhost:80\"\n",
            "/content/app.py:24: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  thread = client.beta.threads.create()\n",
            "/content/app.py:25: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  message = client.beta.threads.messages.create(\n",
            "/content/app.py:30: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  run = client.beta.threads.runs.create(\n",
            "/content/app.py:37: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  run_status = client.beta.threads.runs.retrieve(\n",
            "/content/app.py:49: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n",
            "/content/app.py:24: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  thread = client.beta.threads.create()\n",
            "/content/app.py:25: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  message = client.beta.threads.messages.create(\n",
            "/content/app.py:30: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  run = client.beta.threads.runs.create(\n",
            "/content/app.py:37: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  run_status = client.beta.threads.runs.retrieve(\n",
            "/content/app.py:49: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
            "  messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```python\n",
        "# Your Streamlit toolbox, to further customize your app!\n",
        "\n",
        "\n",
        "#Text\n",
        "st.write(\"text\")\n",
        "\n",
        "#Title\n",
        "st.title('title')\n",
        "\n",
        "#Header\n",
        "st.header('header')\n",
        "\n",
        "#Slider\n",
        "value = st.slider('variable')\n",
        "\n",
        "#Table\n",
        "st.table(dataframe) # Replace with your own Pandas dataframe variable\n",
        "\n",
        "#Matplotlib Figure\n",
        "st.pyplot(fig) # Replace with your own Matplotlib figure variable\n",
        "\n",
        "#Image\n",
        "st.image(image, caption='Image Caption') # Replace with your own image variable\n",
        "\n",
        "#Button\n",
        "pressed = st.button('Button Name')\n",
        "\n",
        "#Checkbox\n",
        "checked = st.checkbox('Checkbox Name')\n",
        "\n",
        "#File Input\n",
        "uploaded_file = st.file_uploader(\"Upload File\")\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    pass #Do something here!\n",
        "```"
      ],
      "metadata": {
        "id": "Vhn2j7uO9czf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations, that's the end of this project! Show off your AI assistant and use it to supercharge your studying! ⚡"
      ],
      "metadata": {
        "id": "0McJbf50TS5s"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}